#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import json
import os
from datetime import datetime

print("=== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹ ===")

def scrape_campaigns():
    print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
    
    # â˜…ç¢ºå®Ÿã«ç”Ÿæˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥æœ¬èªã‚‚OKï¼‰
    campaigns = [
        {
            "title": "ã‚³ã‚«ãƒ»ã‚³ãƒ¼ãƒ© å¹´æœ«ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³",
            "products": ["ã‚³ã‚«ãƒ»ã‚³ãƒ¼ãƒ©", "ã‚³ãƒ¼ãƒ©", "ã‚³ã‚«ã‚³ãƒ¼ãƒ©"],
            "stores": ["å…¨å›½ã‚¹ãƒ¼ãƒ‘ãƒ¼", "ã‚³ãƒ³ãƒ“ãƒ‹"],
            "period": "2025-12-01ã€œ2025-12-31",
            "url": "https://www.coca-cola.co.jp/campaign",
            "scraped_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        },
        {
            "title": "ãƒãƒ†ãƒˆãƒãƒƒãƒ—ã‚¹ ãŠæ­£æœˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³", 
            "products": ["ãƒãƒ†ãƒ", "ãƒãƒ†ãƒˆãƒãƒƒãƒ—ã‚¹", "ã‚«ãƒ©ãƒ ãƒ¼ãƒãƒ§"],
            "stores": ["ã‚¹ãƒ¼ãƒ‘ãƒ¼", "ã‚³ãƒ³ãƒ“ãƒ‹"],
            "period": "2025-12-15ã€œ2026-01-15",
            "url": "https://www.calbee.co.jp/campaign",
            "scraped_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        },
        {
            "title": "ã‚ªãƒ¬ãƒ³ã‚¸ã‚¸ãƒ¥ãƒ¼ã‚¹ å†¬ã®ãƒœãƒ¼ãƒŠã‚¹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³",
            "products": ["ã‚ªãƒ¬ãƒ³ã‚¸ã‚¸ãƒ¥ãƒ¼ã‚¹", "ãƒˆãƒ­ãƒ”ã‚«ãƒ¼ãƒŠ"],
            "stores": ["å…¨å›½"],
            "period": "2025-12-10ã€œ2025-12-25",
            "url": "https://www.tropicana.jp/campaign",
            "scraped_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
    ]
    
    print(f"ç”Ÿæˆã™ã‚‹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ•°: {len(campaigns)}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ç¢ºèª
    filepath = 'campaigns.json'
    print(f"ä¿å­˜å…ˆ: {os.getcwd()}/{filepath}")
    
    try:
        # â˜…UTF-8ã§ç¢ºå®Ÿã«æ›¸ãè¾¼ã¿
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(campaigns, f, ensure_ascii=False, indent=2)
        
        # â˜…ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        if os.path.exists(filepath):
            size = os.path.getsize(filepath)
            print(f"âœ… campaigns.json ç”Ÿæˆå®Œäº†ï¼ã‚µã‚¤ã‚º: {size} bytes")
            
            # ä¸­èº«ã‚’å°‘ã—è¡¨ç¤º
            with open(filepath, 'r', encoding='utf-8') as f:
                preview = json.load(f)
            print(f"ğŸ“Š æœ€åˆã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³: {preview[0]['title'] if preview else 'ç©º'}")
        else:
            print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return False
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = scrape_campaigns()
    print("ğŸ‰ å®Œäº†ï¼" if success else "ğŸ’¥ å¤±æ•—ï¼")
    exit(0)
